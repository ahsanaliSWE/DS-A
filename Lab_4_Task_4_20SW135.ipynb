{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKSDrIfdp9cw"
      },
      "source": [
        "# Mean Normalization\n",
        "\n",
        "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
        "\n",
        "In this lab, you will be performing a different kind of feature scaling known as *mean normalization*. Mean normalization will scale the data, but instead of making the values be between 0 and 1, it will distribute the values evenly in some small interval around zero. For example, if we have a dataset that has values between 0 and 5,000, after mean normalization the range of values will be distributed in some small range around 0, for example between -3 to 3. Because the range of values are distributed evenly around zero, this guarantees that the average (mean) of all elements will be zero. Therefore, when you perform *mean normalization* your data will not only be scaled but it will also have an average of zero.\n",
        "\n",
        "# To Do:\n",
        "\n",
        "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygItcAPNp9c3",
        "outputId": "4886e177-c071-4121-ca87-57f03d4a16fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 20)\n"
          ]
        }
      ],
      "source": [
        "# import NumPy into Python\n",
        "import numpy as np\n",
        "\n",
        "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
        "X = np.random.randint(0, 5001, size=(1000, 20))\n",
        "\n",
        "# print the shape of X\n",
        "print(X.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U3AofwGp9c5"
      },
      "source": [
        "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
        "\n",
        "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
        "\n",
        "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "deA39dA0p9c5"
      },
      "outputs": [],
      "source": [
        "# Average of the values in each column of X\n",
        "ave_cols = np.mean(X, axis=0)\n",
        "\n",
        "# Standard Deviation of the values in each column of X\n",
        "std_cols = np.std(X, axis=0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AMJwSPRp9c6"
      },
      "source": [
        "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABbhXzKhp9c6",
        "outputId": "74bea84f-946f-466c-d15e-ca842539026d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average of each column: [2565.654 2557.075 2558.053 2467.915 2481.384 2515.841 2537.95  2531.416\n",
            " 2453.117 2485.557 2546.54  2480.573 2502.792 2501.864 2573.016 2489.638\n",
            " 2502.95  2525.5   2501.539 2506.857]\n",
            "Standard deviation of each column: [1439.52751633 1442.37685345 1413.35537081 1437.93268124 1415.02294276\n",
            " 1441.83303323 1430.08451761 1452.22574242 1444.74668898 1439.21946442\n",
            " 1409.02893739 1472.02425139 1465.33149312 1428.59046739 1461.83313813\n",
            " 1454.20632063 1408.94737215 1440.17564345 1435.15658396 1410.10895556]\n"
          ]
        }
      ],
      "source": [
        "# Print the shape of ave_cols\n",
        "print(\"Average of each column:\", ave_cols)\n",
        "# Print the shape of std_cols\n",
        "print(\"Standard deviation of each column:\", std_cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnrFmFmwp9c7"
      },
      "source": [
        "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nd8P2jaep9c7",
        "outputId": "9967e3e2-b374-4688-dcfa-1ee50633b611"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean normalized X:\n",
            "[[ 1.27982687  0.03877281 -0.69130031 ...  0.46487385  0.69432215\n",
            "  -0.82962171]\n",
            " [ 1.63063642  0.47277866  0.72801719 ... -0.2898952  -0.0393957\n",
            "  -0.91826734]\n",
            " [ 1.67092742  0.13999462  1.15041626 ...  1.03980373  0.60234612\n",
            "  -1.17994925]\n",
            " ...\n",
            " [ 0.02663791  1.33247077 -0.11112067 ...  0.08853087 -1.32009219\n",
            "  -1.7735204 ]\n",
            " [-1.12304488  1.5390742  -1.44128861 ...  0.61971608 -0.08468693\n",
            "  -0.45092757]\n",
            " [-1.53637494 -0.06730211  1.27494262 ...  1.07938223 -1.55212262\n",
            "   0.1646277 ]]\n"
          ]
        }
      ],
      "source": [
        "# Mean normalize X using broadcasting\n",
        "X_norm = (X - ave_cols) / std_cols\n",
        "\n",
        "print(\"Mean normalized X:\")\n",
        "print(X_norm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sos6Yd8ap9c8"
      },
      "source": [
        "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. You can verify this by filing the code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUF4dVNip9c8",
        "outputId": "be1dd5e7-35fb-4970-c215-f6e44cc61c5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average of all values in X_norm: 2.5934809855243657e-17\n",
            "Average of minimum values in each column of X_norm: -1.7466589674291584\n",
            "Average of maximum values in each column of X_norm: 1.727431768207003\n"
          ]
        }
      ],
      "source": [
        "# Print the average of all the values of X_norm\n",
        "average_all = np.mean(X_norm)\n",
        "print(\"Average of all values in X_norm:\", average_all)\n",
        "\n",
        "# Print the average of the minimum value in each column of X_norm\n",
        "average_min_col = np.mean(np.min(X_norm, axis=0))\n",
        "print(\"Average of minimum values in each column of X_norm:\", average_min_col)\n",
        "\n",
        "# Print the average of the maximum value in each column of X_norm\n",
        "average_max_col = np.mean(np.max(X_norm, axis=0))\n",
        "print(\"Average of maximum values in each column of X_norm:\", average_max_col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "440MFTB0p9c8"
      },
      "source": [
        "You should note that since $X$ was created using random integers, the above values will vary.\n",
        "\n",
        "# Data Separation\n",
        "\n",
        "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
        "\n",
        "1. A Training Set\n",
        "2. A Cross Validation Set\n",
        "3. A Test Set\n",
        "\n",
        "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data.\n",
        "\n",
        "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
        "\n",
        "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPscpJFLp9c8",
        "outputId": "08b7a473-9f8a-4b4a-c7e3-22a00e540208"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 3, 4, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# We create a random permutation of integers 0 to 4\n",
        "np.random.permutation(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1dCeEP_p9c9"
      },
      "source": [
        "# To Do\n",
        "\n",
        "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdAMhDYCp9c9",
        "outputId": "d8e39069-9c71-4aab-9f88-4dc60857b219"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random permutation of row indices: [969 701 978 948 849  82 497 743 352 658 512 342 369 474 898 450 296  18\n",
            " 791 414 916 378 594 706 715 604 579 509 690 337 887 396 837 859 503 986\n",
            " 281 449 203 105 851 353 332 448 341 635 905 510 197 829 561  22 108 481\n",
            " 880 235 744  17 125  93 646 365 242 542 731 950  77 955 823 567 195 224\n",
            " 384 515 103 836 610 392 668 389 456 153  54 564  56 331 924 209 728 463\n",
            " 886 928 885 954 393 633 531 949 292 314 104 488 762 606 162 408 541 267\n",
            " 479 853 754 565 151 304 159 961 875 489 827 339 572 926 936 199 705 308\n",
            " 819 319 113 444 687 480 603 593  45 987 618 394 310   2  16 759 521 753\n",
            " 724 349  85 910 217 758 152 129 655 615 477 464 861 704 148 557 600 220\n",
            " 943 126 664   5 717 832 502 169 381 932 628 401 252 595 768 749 617 738\n",
            " 386 204 662 432 112 736 672 362  44 424 136 622 960 772 356  39  53 782\n",
            " 663 651 650 483 193 940 997 140 933  95 115 677 726 609 805 657 694 900\n",
            " 812 778 760 679 446 667 410 358 200 132 952 196 253 808 524 240 295 739\n",
            " 147 457 965 413 991  26 852 784 201  13 405 735 798 637 210 485 889 864\n",
            " 385 285 119 591 828 511 212 325 416 707 437 896 370 436 723 230 379 174\n",
            " 669 790 347  10  66 776   3 856 359  75 258 289 513 154 429 246 613 560\n",
            " 208 671 164 282 944 218 537 268 598 907 175 233  41 133 683 278 545 127\n",
            "  79 592 114  73 580 368 802  58   8 527  80 693  94 970 870 355  84 848\n",
            " 179 372 585 757 636 824 109 927 660 316 666 775 498  67 839 605 323 925\n",
            " 794 423 813 306 930 746 882 611 771 941 548 144 187 419 534 461 168 644\n",
            " 508 720 478 300 647 326 626 473 862 120 789 192 137 689 409 206   6 878\n",
            " 993 145 487 959 374 453 165  61 956 732 816 807 458 745 194  30 302 468\n",
            " 980 166 399 763 554 122 303 981 573 451 995 170 888 186 947 443 380 756\n",
            " 680 971 407 367 311 846 866 496 288 188 219 435 601  31 460 867 484 505\n",
            " 539 549 994 420  24 919 402 796 530 682 121 177 216 620 992 770 403 344\n",
            " 788 434 146 599 259 873 996 876 627  64 313  63 102 415 214 779 143 467\n",
            " 571 160 553 231 459 562 532 716 546 514  35 793 178 238 183 871 840 976\n",
            " 685 237 608 430 860 260 972  33 632 373 661 271 335 755 340 638 578 550\n",
            " 942  37 582 540 244 934 714 135 834 156 139  32 309 241 184  62 245 100\n",
            " 243 983 773 587 455 979 395 648 629 533 433 357 999 621 697 305 255 619\n",
            " 291 516 675 691 699 765   0 684 198 958   4 286 656 375 232 247 134 469\n",
            " 525 917 718 387 963 447   9 161 124 653 939 506 703 317 863 520 570 616\n",
            " 730 649 737 328 722 767 563 982 229 417 584 376 412 551 659 482 801 558\n",
            "  28  74 612 404  21 998 290 301 614 574 228  89 729 830  48 596  12 974\n",
            "  50 338 777 466 163 785  15 698 257 279 297 202 800 445 517  90 708 634\n",
            " 843 222 493 490 734 428 366 877 968 439  42 700 494  70 911 695 897 130\n",
            " 913 544 476 322 552 264 107 725 426 452 555 535  91 967 821 111  38 486\n",
            " 676 764  25 643 556 185 891 711 787 190 814 336 581 748 966 491 330 131\n",
            " 261 709 654 872 774  55 921 239 857 854 792 211 142 422 298 962 158 841\n",
            "  19 623 280 844 850 350 116 182  81 411 538 751 321 406 833 275 588 868\n",
            " 938 504 929  99 727 440 713 226 842  47 799 780 327 348 171 918  71 568\n",
            " 123 855  20 631 696 845 681 575   1  72 783 518 822 892 678 847 719 988\n",
            " 262  92  46  69 442 630 543 334 269 890 425 733 920 825 180 307 973 750\n",
            "  59 884 894 586  78 522 284 899 577 205 150 766  51 874 364 495 945 500\n",
            " 363 149 686 421 931 529  98  11 645  14  83 221 128 397 383 869 390 270\n",
            " 431 333 167 673 236 990 607 590 418 975 977 946 639 893 989 277 315  68\n",
            " 499 234 786 346 583 287 172 915 263 173 106 377 811  87 312 721 747 803\n",
            " 710 118 674 742 806 110 625 914 902 640 547 248 345 953 382 865 692 576\n",
            " 602 797 985 922 702 804 462 360 191 769 901 908 964 299 181 454 519  43\n",
            "  36 225 881 391 752 528 935 265 624 470 688 984 712 957 441  97  88  23\n",
            " 912 427 906 227 207 526 589 741 740 670 324 923 809 471 879  49 818 351\n",
            "  65 318 904 472 276 256 903 371 223  27 250 817 652 272 858 213 566 523\n",
            " 831 155  76 138 215 536 883 400 507  57 826 838  29 492 761  52 141 249\n",
            " 795 937 781 835 266  40 101 388  60 254 283 273 820 810 320 909  96 569\n",
            " 642 559 597 117 665 251 641  86 438 329 895 354 475 815 361 274 176 294\n",
            " 157 189  34 951 501 343 293   7 465 398]\n"
          ]
        }
      ],
      "source": [
        "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
        "row_indices =  np.random.permutation(X_norm.shape[0])\n",
        "print(\"Random permutation of row indices:\", row_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LraK4SHp9c9"
      },
      "source": [
        "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JzzEVqKMp9c9"
      },
      "outputs": [],
      "source": [
        "# Make any necessary calculations.\n",
        "# You can save your calculations into variables to use later.\n",
        "\n",
        "# Calculate the number of rows for each set\n",
        "num_rows = X_norm.shape[0]\n",
        "num_train = int(0.6 * num_rows)\n",
        "num_cross_val = int(0.2 * num_rows)\n",
        "num_test = num_rows - num_train - num_cross_val\n",
        "\n",
        "# Create a Training Set\n",
        "X_train = X_norm[row_indices[:num_train]]\n",
        "\n",
        "# Create a Cross Validation Set\n",
        "X_crossVal = X_norm[row_indices[num_train:num_train + num_cross_val]]\n",
        "\n",
        "# Create a Test Set\n",
        "X_test = X_norm[row_indices[num_train + num_cross_val:]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Bdt163Ep9c-"
      },
      "source": [
        "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iO6tGbIvp9c-",
        "outputId": "fb8dd268-545c-418c-b116-b7969d37972f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (600, 20)\n",
            "Shape of X_crossVal: (200, 20)\n",
            "Shape of X_test: (200, 20)\n"
          ]
        }
      ],
      "source": [
        "# Print the shape of X_train\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "\n",
        "# Print the shape of X_crossVal\n",
        "print(\"Shape of X_crossVal:\", X_crossVal.shape)\n",
        "\n",
        "# Print the shape of X_test\n",
        "print(\"Shape of X_test:\", X_test.shape)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}